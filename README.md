# Welcome to Kaggle Pet Competition Course


## Part I: Machine Learning Essentials

### Week 1 (Nov 13) basic python tutorial
- [Key concepts in machine learning](https://towardsdatascience.com/machine-learning-basics-part-1-a36d38c7916)
- [How to win Kaggle competitions](https://docs.google.com/document/d/14KDMW_o1yflcZd4E0PSlKxzI68zdHG20Qz6X5wmkgSA/edit?usp=sharing)
- [Coding Environment](https://docs.google.com/presentation/d/1cYZACKaB7e2vRZAv8Oe1GcVy6U_xBeOoeptJsl3KZtI/edit?usp=sharing)
- [Python Tutorial #1: Basics Numpy]
- [Python Tutorial #2: Basics Pandas]


### Week 2 (Nov 20) EDA & Feature Engineering
- [Feature Engineering](https://docs.google.com/presentation/d/13gwvLolY0Ug_WKROeVYpHpblWhNhvmj3DskSxsu3Ta0/edit?usp=sharing)
- [Python Tutorial #3: Basic data processing and visualization]
- [Python Tutorial #4: Feature engineering]


### Week 3 (Nov 27) CV and linear models
- [Python Tutorial #5: Cross validation, grid search for parameter selection]
- [Python Tutorial #6: Linear regression, Ridge, Lasso models]

### Week 4 (Dec 4) Tree based models, Xgboost and LightGBM
- [Python Tutorial #7: Decision Trees]
- [Gini impurity in decision tree CART algorithm](https://victorzhou.com/blog/gini-impurity/)
- [Python Tutorial #8: Xgboost & LightGBM]
- [Gradient boosting explained](https://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/)

## Part II: NLP advanced models
### Week 5 (Dec 11) Deep neural network
- [DNN](https://docs.google.com/presentation/d/1XcIfz7TBiMcuJSdHLzdzekB-GxCbHLu9V01tM3H9PFU/edit#slide=id.p)
- [Python Tutorial #9: Deep NN]

### Week 6 (Dec 18) CNN
- [Python Tutorial #10: CNN]

## Part III: Kaggle notebook & group sessions
### Week 7 (Dec 25)
- Group 1
- Group 2
- Group 3
### Week 8 (Jan 1)
- Group 1
- Group 2
- Group 3
### Week 9 (Jan 8)
- Group 1
- Group 2
- Group 3

## Submission Deadline Jan 13

